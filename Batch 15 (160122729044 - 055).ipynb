{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31013,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install medmnist","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-26T07:57:06.569932Z","iopub.execute_input":"2025-04-26T07:57:06.570240Z","iopub.status.idle":"2025-04-26T07:58:17.693443Z","shell.execute_reply.started":"2025-04-26T07:57:06.570216Z","shell.execute_reply":"2025-04-26T07:58:17.692816Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, WeightedRandomSampler\nfrom torchvision import transforms\nimport medmnist\nfrom medmnist import INFO\nimport numpy as np\nfrom tqdm import tqdm\nfrom sklearn.utils.class_weight import compute_class_weight\nimport os\nimport signal\nimport sys\nimport json","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T07:58:17.694910Z","iopub.execute_input":"2025-04-26T07:58:17.695115Z","iopub.status.idle":"2025-04-26T07:58:25.420267Z","shell.execute_reply.started":"2025-04-26T07:58:17.695097Z","shell.execute_reply":"2025-04-26T07:58:25.419426Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Handle interruptions gracefully\ndef handle_interrupt(signum, frame):\n    print(\"\\nTraining interrupted! Saving model and metrics...\")\n    save_checkpoint()\n    sys.exit(1)\n\nsignal.signal(signal.SIGINT, handle_interrupt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T07:58:25.421204Z","iopub.execute_input":"2025-04-26T07:58:25.421696Z","iopub.status.idle":"2025-04-26T07:58:25.428098Z","shell.execute_reply.started":"2025-04-26T07:58:25.421675Z","shell.execute_reply":"2025-04-26T07:58:25.427557Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Enable GPU memory optimizations for Colab\nos.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n\n# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ntorch.backends.cudnn.benchmark = True\n\n# Set random seeds for reproducibility\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n# Mount Google Drive\n# from google.colab import drive\n# drive.mount('/content/drive')\n# os.makedirs('/content/drive/MyDrive/pathmnist', exist_ok=True)\n\n\nconfig = {\n    'data_flag': 'pathmnist',  # Example dataset from MedMNIST\n    'batch_size': 128,\n    'max_epochs': 50,\n    'early_stop_patience': 5,\n    'checkpoint_path': '/content/checkpoint.pth',\n    'best_model_path': '/content/best_model.pth',\n    'metrics_path': '/content/training_metrics.json',\n    'resume_training': False  # Set to True to resume from checkpoint\n}\n\nprint(f\"Using device: {device}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T07:58:25.429117Z","iopub.execute_input":"2025-04-26T07:58:25.429336Z","iopub.status.idle":"2025-04-26T07:58:25.877035Z","shell.execute_reply.started":"2025-04-26T07:58:25.429320Z","shell.execute_reply":"2025-04-26T07:58:25.876293Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Data Preparation\ninfo = INFO[config['data_flag']]\nDataClass = getattr(medmnist, info['python_class'])\n\n# Compute class weights\ntrain_dataset = DataClass(split='train', download=True)\ntrain_labels = [label.item() for _, label in train_dataset]\nclass_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\nclass_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n\n# Data Augmentation\ntrain_transform = transforms.Compose([\n    transforms.RandomResizedCrop(28, scale=(0.8, 1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomRotation(15),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    transforms.RandomErasing(p=0.5, scale=(0.02, 0.1))\n])\n\ntest_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Datasets and DataLoaders\ntrain_dataset = DataClass(split='train', transform=train_transform)\nval_dataset = DataClass(split='val', transform=test_transform)\ntest_dataset = DataClass(split='test', transform=test_transform)\n\nsampler = WeightedRandomSampler(\n    weights=class_weights[train_labels], \n    num_samples=len(train_dataset),\n    replacement=True\n)\n\ntrain_loader = DataLoader(train_dataset, batch_size=config['batch_size'], sampler=sampler,\n                         num_workers=4, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False,\n                       num_workers=4, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False,\n                        num_workers=4, pin_memory=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T07:58:25.878918Z","iopub.execute_input":"2025-04-26T07:58:25.879121Z","iopub.status.idle":"2025-04-26T07:59:47.737048Z","shell.execute_reply.started":"2025-04-26T07:58:25.879104Z","shell.execute_reply":"2025-04-26T07:59:47.736486Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Model Components\nclass SqueezeExcitation(nn.Module):\n    def __init__(self, channel, reduction=16):\n        super().__init__()\n        self.avgpool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Sequential(\n            nn.Linear(channel, channel // reduction),\n            nn.ReLU(),\n            nn.Linear(channel // reduction, channel),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        b, c, _, _ = x.size()\n        y = self.avgpool(x).view(b, c)\n        y = self.fc(y).view(b, c, 1, 1)\n        return x * y.expand_as(x)\n\nclass MBConvBlock(nn.Module):\n    def __init__(self, in_c, out_c, expansion=4):\n        super().__init__()\n        hidden_dim = in_c * expansion\n        self.use_residual = in_c == out_c\n        \n        self.block = nn.Sequential(\n            nn.Conv2d(in_c, hidden_dim, 1, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            nn.ReLU(),\n            nn.Conv2d(hidden_dim, hidden_dim, 3, padding=1, groups=hidden_dim, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            nn.ReLU(),\n            SqueezeExcitation(hidden_dim),\n            nn.Conv2d(hidden_dim, out_c, 1, bias=False),\n            nn.BatchNorm2d(out_c)\n        )\n\n    def forward(self, x):\n        if self.use_residual:\n            return x + self.block(x)\n        return self.block(x)\n\nclass EfficientVSSBlock(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.dwconv = nn.Conv2d(dim, dim, kernel_size=3, padding=1, groups=dim)\n        \n        possible_groups = [32, 16, 8, 4, 2, 1]\n        self.num_groups = next((g for g in possible_groups if dim % g == 0), 1)\n        \n        self.norm = nn.GroupNorm(num_groups=self.num_groups, num_channels=dim)\n        self.pwconv1 = nn.Linear(dim, 2 * dim)\n        self.act = nn.GELU()\n        self.pwconv2 = nn.Linear(2 * dim, dim)\n        self.gamma = nn.Parameter(torch.ones(1, dim, 1, 1) * 1e-6)\n        self.se = SqueezeExcitation(dim)\n\n    def forward(self, x):\n        input = x\n        x = self.dwconv(x)\n        x = self.se(x)\n        \n        b, c, h, w = x.shape\n        x = x.permute(0, 2, 3, 1).contiguous()\n        \n        if self.num_groups > 1:\n            x = x.reshape(b * h * w, c)\n            x = self.norm(x)\n            x = x.reshape(b, h, w, c)\n        else:\n            x = self.norm(x)\n        \n        x = self.pwconv1(x)\n        x = self.act(x)\n        x = self.pwconv2(x)\n        \n        x = x.permute(0, 3, 1, 2).contiguous()\n        return input + self.gamma * x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T07:59:47.737741Z","iopub.execute_input":"2025-04-26T07:59:47.737992Z","iopub.status.idle":"2025-04-26T07:59:47.749886Z","shell.execute_reply.started":"2025-04-26T07:59:47.737974Z","shell.execute_reply":"2025-04-26T07:59:47.749315Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Main Model Architecture\nclass EnhancedPathoNet(nn.Module):\n    def __init__(self, num_classes=9):\n        super().__init__()\n        \n        # Stem\n        self.stem = nn.Sequential(\n            nn.Conv2d(3, 32, 3, stride=2, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.Conv2d(32, 32, 3, stride=1, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU()\n        )\n        \n        # Encoder\n        self.encoder = nn.Sequential(\n            MBConvBlock(32, 64),\n            MBConvBlock(64, 128),\n            MBConvBlock(128, 256),\n            MBConvBlock(256, 512),\n            nn.Conv2d(512, 512, 3, padding=1, groups=512),\n            nn.Conv2d(512, 1024, 1),\n            nn.BatchNorm2d(1024),\n            nn.ReLU()\n        )\n        \n        # Transformer\n        self.vss_block = EfficientVSSBlock(1024)\n        \n        # Multi-Scale Features\n        self.output1 = nn.Sequential(\n            SqueezeExcitation(1024),\n            nn.AdaptiveAvgPool2d(1),\n            nn.Flatten(),\n            nn.Linear(1024, 512)\n        )\n        \n        self.output2 = nn.Sequential(\n            nn.Conv2d(1024, 512, 1),\n            nn.BatchNorm2d(512),\n            nn.ReLU()\n        )\n        \n        # Decoders\n        self.decoder1 = nn.Sequential(\n            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n            nn.Conv2d(512, 256, 3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU()\n        )\n        \n        self.decoder2 = nn.Sequential(\n            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n            nn.Conv2d(256, 128, 3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU()\n        )\n        \n        # Skip Connections\n        self.skip1 = nn.Conv2d(1024, 256, 1)\n        self.skip2 = nn.Conv2d(512, 128, 1)\n        \n        # Classifier\n        self.classifier = nn.Sequential(\n            nn.Conv2d(128, 256, 3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.AdaptiveAvgPool2d(1),\n            nn.Flatten(),\n            nn.Dropout(0.3),\n            nn.Linear(256, num_classes))\n        \n        # Initialize weights\n        self._init_weights()\n\n    def _init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            elif isinstance(m, nn.Linear):\n                nn.init.xavier_normal_(m.weight)\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n\n    def forward(self, x):\n        # Stem\n        x = self.stem(x)\n        \n        # Encoder\n        x = self.encoder(x)\n        \n        # Transformer\n        x = self.vss_block(x)\n        \n        # Multi-path\n        global_feat = self.output1(x)\n        spatial_feat = self.output2(x)\n        \n        # Decoder with skip connections\n        d1 = self.decoder1(spatial_feat)\n        skip1 = F.interpolate(self.skip1(x), size=d1.shape[2:], mode='bilinear', align_corners=True)\n        \n        d2 = self.decoder2(d1 + skip1)\n        skip2 = F.interpolate(self.skip2(spatial_feat), size=d2.shape[2:], mode='bilinear', align_corners=True)\n        \n        out = self.classifier(d2 + skip2)\n        return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T07:59:47.750634Z","iopub.execute_input":"2025-04-26T07:59:47.750847Z","iopub.status.idle":"2025-04-26T07:59:47.764127Z","shell.execute_reply.started":"2025-04-26T07:59:47.750832Z","shell.execute_reply":"2025-04-26T07:59:47.763565Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Loss Functions\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=0.75, gamma=2.0):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n\n    def forward(self, inputs, targets):\n        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n        pt = torch.exp(-ce_loss)\n        focal_loss = (self.alpha * (1-pt)**self.gamma * ce_loss).mean()\n        return focal_loss\n\n# class CombinedLoss(nn.Module):\n#     def __init__(self, class_weights, alpha=0.75, gamma=2.0, label_smoothing=0.2):\n#         super().__init__()\n#         self.ce_loss = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=label_smoothing)\n#         self.focal_loss = FocalLoss(alpha=alpha, gamma=gamma)\n        \n#     def forward(self, inputs, targets):\n#         return self.ce_loss(inputs, targets) + self.focal_loss(inputs, targets)\n\nclass CombinedLoss(nn.Module):\n    def __init__(self, class_weights, alpha=0.75, gamma=2.0, label_smoothing=0.2):\n        super().__init__()\n        self.focal = FocalLoss(alpha=alpha, gamma=gamma)\n        self.class_weights = class_weights\n        self.label_smoothing = label_smoothing\n        self.ce_loss = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=label_smoothing)\n\n    def forward(self, inputs, targets):\n        loss_focal = self.focal(inputs, targets)\n        loss_ce = self.ce_loss(inputs, targets)\n        return 0.5 * loss_focal + 0.5 * loss_ce\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T07:59:47.764715Z","iopub.execute_input":"2025-04-26T07:59:47.764986Z","iopub.status.idle":"2025-04-26T07:59:47.779405Z","shell.execute_reply.started":"2025-04-26T07:59:47.764954Z","shell.execute_reply":"2025-04-26T07:59:47.778794Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training State\ntraining_state = {\n    'epoch': 0,\n    'best_val_acc': 0,\n    'best_epoch': 0,\n    'early_stop_counter': 0,\n    'train_loss_history': [],\n    'train_acc_history': [],\n    'val_loss_history': [],\n    'val_acc_history': []\n}\n\ndef save_checkpoint():\n    checkpoint = {\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'scheduler_state_dict': scheduler.state_dict(),\n        'scaler_state_dict': scaler.state_dict(),\n        'training_state': training_state\n    }\n    torch.save(checkpoint, config['checkpoint_path'])\n    \n    with open(config['metrics_path'], 'w') as f:\n        json.dump(training_state, f)\n    \n    print(f\"Checkpoint saved at epoch {training_state['epoch']}\")\n\ndef load_checkpoint():\n    if os.path.exists(config['checkpoint_path']):\n        checkpoint = torch.load(config['checkpoint_path'])\n        model.load_state_dict(checkpoint['model_state_dict'])\n        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n        scaler.load_state_dict(checkpoint['scaler_state_dict'])\n        \n        global training_state\n        training_state = checkpoint['training_state']\n        \n        if os.path.exists(config['metrics_path']):\n            with open(config['metrics_path'], 'r') as f:\n                training_state.update(json.load(f))\n        \n        print(f\"Resuming training from epoch {training_state['epoch'] + 1}\")\n        return True\n    return False\n\ndef check_early_stopping():\n    if training_state['early_stop_counter'] >= config['early_stop_patience']:\n        print(f\"\\nEarly stopping triggered! No improvement for {config['early_stop_patience']} epochs.\")\n        save_checkpoint()\n        return True\n    return False\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T07:59:47.780124Z","iopub.execute_input":"2025-04-26T07:59:47.780358Z","iopub.status.idle":"2025-04-26T07:59:47.795110Z","shell.execute_reply.started":"2025-04-26T07:59:47.780335Z","shell.execute_reply":"2025-04-26T07:59:47.794535Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize Model and Training Components\nmodel = EnhancedPathoNet().to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=1e-5)\ncriterion = CombinedLoss(class_weights=class_weights)\nscaler = torch.cuda.amp.GradScaler()\nscheduler = torch.optim.lr_scheduler.OneCycleLR(\n    optimizer, max_lr=5e-4, steps_per_epoch=len(train_loader), epochs=config['max_epochs'],\n    pct_start=0.1, anneal_strategy='cos'\n)\n\n# Resume training if requested\nif config['resume_training'] and load_checkpoint():\n    start_epoch = training_state['epoch'] + 1\nelse:\n    start_epoch = 0\n\n# Training Loop\nfor epoch in range(start_epoch, config['max_epochs']):\n    model.train()\n    train_loss = correct = total = 0\n    \n    for inputs, targets in tqdm(train_loader, desc=f'Epoch {epoch+1}/{config[\"max_epochs\"]}'):\n        inputs, targets = inputs.to(device), targets.squeeze().long().to(device)\n        \n        optimizer.zero_grad(set_to_none=True)\n        with torch.cuda.amp.autocast():\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n        \n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        scheduler.step()\n        \n        train_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += targets.size(0)\n        correct += predicted.eq(targets).sum().item()\n    \n    # Validation\n    model.eval()\n    val_loss = val_correct = val_total = 0\n    with torch.no_grad():\n        for inputs, targets in val_loader:\n            inputs, targets = inputs.to(device), targets.squeeze().long().to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            \n            val_loss += loss.item()\n            _, predicted = outputs.max(1)\n            val_total += targets.size(0)\n            val_correct += predicted.eq(targets).sum().item()\n    \n    # Calculate metrics\n    train_acc = 100 * correct / total\n    val_acc = 100 * val_correct / val_total\n    avg_train_loss = train_loss / len(train_loader)\n    avg_val_loss = val_loss / len(val_loader)\n    \n    # Update training state\n    training_state['epoch'] = epoch\n    training_state['train_loss_history'].append(avg_train_loss)\n    training_state['train_acc_history'].append(train_acc)\n    training_state['val_loss_history'].append(avg_val_loss)\n    training_state['val_acc_history'].append(val_acc)\n    \n    # Check for best model\n    if val_acc > training_state['best_val_acc']:\n        training_state['best_val_acc'] = val_acc\n        training_state['best_epoch'] = epoch\n        training_state['early_stop_counter'] = 0\n        torch.save(model.state_dict(), config['best_model_path'])\n        print(f'New best model saved with val_acc: {val_acc:.2f}% at epoch {epoch+1}')\n    else:\n        training_state['early_stop_counter'] += 1\n    \n    print(f'Epoch {epoch+1}: '\n          f'Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}%, '\n          f'Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n    \n    # Save checkpoint periodically\n    if (epoch + 1) % 5 == 0:\n        save_checkpoint()\n    \n    # Early stopping check\n    if check_early_stopping():\n        break\n\n# Final save\nsave_checkpoint()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T07:59:47.795860Z","iopub.execute_input":"2025-04-26T07:59:47.796088Z","iopub.status.idle":"2025-04-26T12:16:59.710111Z","shell.execute_reply.started":"2025-04-26T07:59:47.796065Z","shell.execute_reply":"2025-04-26T12:16:59.709187Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Testing\nmodel.load_state_dict(torch.load(config['best_model_path']))\nmodel.eval()\ntest_correct = test_total = 0\nwith torch.no_grad():\n    for inputs, targets in test_loader:\n        inputs, targets = inputs.to(device), targets.squeeze().long().to(device)\n        outputs = model(inputs)\n        _, predicted = outputs.max(1)\n        test_total += targets.size(0)\n        test_correct += predicted.eq(targets).sum().item()\n\nprint(f'\\nFinal Test Accuracy: {100 * test_correct / test_total:.2f}%')\n\n# Save final model\ntorch.save(model.state_dict(), 'pathonet_final.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T12:16:59.711358Z","iopub.execute_input":"2025-04-26T12:16:59.711671Z","iopub.status.idle":"2025-04-26T12:17:17.462924Z","shell.execute_reply.started":"2025-04-26T12:16:59.711639Z","shell.execute_reply":"2025-04-26T12:17:17.461903Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom tqdm import tqdm\n\ndef evaluate_and_visualize(model, dataloader, class_names, save_path=\"results\"):\n    model.eval()\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for inputs, targets in tqdm(dataloader, desc=\"Evaluating\"):\n            inputs, targets = inputs.to(device), targets.to(device)\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(targets.cpu().numpy())\n\n    cm = confusion_matrix(all_labels, all_preds)\n    report = classification_report(all_labels, all_preds, target_names=class_names, output_dict=True)\n    report_df = pd.DataFrame(report).transpose()\n\n    # Save classification report\n    os.makedirs(save_path, exist_ok=True)\n    report_df.to_csv(os.path.join(save_path, \"classification_report.csv\"), index=True)\n\n    # Save confusion matrix plot\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n    plt.title(\"Confusion Matrix\")\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"True\")\n    plt.tight_layout()\n    plt.savefig(os.path.join(save_path, \"confusion_matrix.png\"))\n    plt.close()\n\n    print(\"Confusion Matrix and Classification Report saved to:\", save_path)\n\n# Example usage\nif __name__ == \"__main__\":\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    model = EnhancedPathoNet(num_classes=9).to(device)\n    \n    # --- CORRECTION HERE ---\n    model.load_state_dict(torch.load(\"pathonet_final.pth\", map_location=device))\n    \n    # You showed that 'info' is a dictionary with 'label' keys like '0', '1', etc\n    class_names = [info['label'][str(i)] for i in range(9)]\n    \n    evaluate_and_visualize(model, test_loader, class_names)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T12:29:44.716617Z","iopub.execute_input":"2025-04-26T12:29:44.717216Z","iopub.status.idle":"2025-04-26T12:30:03.874585Z","shell.execute_reply.started":"2025-04-26T12:29:44.717194Z","shell.execute_reply":"2025-04-26T12:30:03.873588Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image\nimport IPython.display as display\n\n# Display the Classification Report\nreport_df = pd.read_csv('results/classification_report.csv', index_col=0)\ndisplay.display(report_df)\n\n# Display the Confusion Matrix Image\nimg = Image.open('results/confusion_matrix.png')\nplt.figure(figsize=(10, 8))\nplt.imshow(img)\nplt.axis('off')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T12:30:53.345198Z","iopub.execute_input":"2025-04-26T12:30:53.345813Z","iopub.status.idle":"2025-04-26T12:30:53.818300Z","shell.execute_reply.started":"2025-04-26T12:30:53.345783Z","shell.execute_reply":"2025-04-26T12:30:53.817605Z"}},"outputs":[],"execution_count":null}]}